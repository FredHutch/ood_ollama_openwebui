#!/usr/bin/env bash
module purge

module load Apptainer uv

# Output debug info
module list



  

echo port is $port
echo host is $host

echo
echo ollama_port is $ollama_port
echo ------


# excerpt from https://discourse.openondemand.org/t/avoid-launching-a-web-browser/4060/14?u=dtenenba


<%

nv = ""
if context.want_gpu == "1"
  nv = " --nv "
end


%>


set -x
set -e

export OLLAMA_HOST=${host}:${ollama_port}
export OLLAMA_MODELS=/app/ollama/models
export OLLAMA_CHAT_HOST=0.0.0.0
export OLLAMA_CHAT_URL_PREFIX=/node/${host}/${port}
echo "OLLAMA_CHAT_URL_PREFIX=${OLLAMA_CHAT_URL_PREFIX}"
apptainer run  <%= nv %>  --env OLLAMA_HOST=$localhost:${ollama_port} -B /app/ollama/models:/app/ollama/models:ro --writable-tmpfs --env OLLAMA_MODELS=${OLLAMA_MODELS} https://sif-registry.fredhutch.org/ollama_latest.sif  serve  &

# needs (?) to be in a slightly different form for the UI:
export OLLAMA_HOST=http://${host}:${ollama_port}




uv run --with git+https://github.com/FredHutch/ollama-chat.git ollama-chat -p ${port} -x -n

# /home/dtenenba/dev/ollama-chat/.venv/bin/ollama-chat -p ${port} -n -x




